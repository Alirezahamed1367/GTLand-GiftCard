"""
Data Importer - ÙˆØ§Ø³Ø· Ø¨ÛŒÙ† Google Sheets Ùˆ Dynamic System
Ø§ÛŒÙ† Ù…Ø§Ú˜ÙˆÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ø±Ø§ Ø§Ø² Google Sheets Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø¯Ø± SheetImport/RawData Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
"""
from typing import List, Dict, Optional, Tuple
from sqlalchemy.orm import Session
from datetime import datetime
import json

from app.core.google_sheets import GoogleSheetExtractor
from app.models.financial import SheetImport, RawData, SheetType
from app.core.logger import app_logger


class DataImporter:
    """Ú©Ù„Ø§Ø³ import Ø¯Ø§Ø¯Ù‡ Ø§Ø² Google Sheets Ø¨Ù‡ Ø³ÛŒØ³ØªÙ… Ø¯ÛŒÙ†Ø§Ù…ÛŒÚ©"""
    
    def __init__(self, db_session: Session):
        self.db = db_session
        self.logger = app_logger
        self.sheet_extractor = GoogleSheetExtractor()
    
    def import_from_google_sheet(
        self,
        sheet_url: str,
        worksheet_name: str,
        sheet_name: str,
        sheet_type: SheetType,
        platform: Optional[str] = None,
        skip_header: bool = True
    ) -> Tuple[bool, str, Optional[int]]:
        """
        Import Ø¯Ø§Ø¯Ù‡ Ø§Ø² Google Sheet
        
        Args:
            sheet_url: Ø¢Ø¯Ø±Ø³ Google Sheet
            worksheet_name: Ù†Ø§Ù… worksheet
            sheet_name: Ù†Ø§Ù… Ø¯Ù„Ø®ÙˆØ§Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† import
            sheet_type: Ù†ÙˆØ¹ Ø´ÛŒØª (PURCHASE/SALE/BONUS)
            platform: Ù¾Ù„ØªÙØ±Ù… (ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ SALE Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª)
            skip_header: Ø¢ÛŒØ§ Ø³Ø·Ø± Ø§ÙˆÙ„ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ø¨Ú¯ÛŒØ±Ø¯ØŸ
        
        Returns:
            (success, message, sheet_import_id)
        """
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ platform Ø¨Ø±Ø§ÛŒ SALE
            if sheet_type == SheetType.SALE and not platform:
                return False, "âŒ Ø¨Ø±Ø§ÛŒ Ø´ÛŒØª ÙØ±ÙˆØ´ØŒ ØªØ¹ÛŒÛŒÙ† platform Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª!", None
            
            self.logger.info(f"ğŸ”„ Ø´Ø±ÙˆØ¹ import Ø§Ø² '{worksheet_name}'...")
            
            # Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            all_data = self.sheet_extractor.get_all_data(sheet_url, worksheet_name)
            
            if not all_data:
                return False, "âŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø± worksheet ÛŒØ§ÙØª Ù†Ø´Ø¯!", None
            
            # Ø­Ø°Ù Ù‡Ø¯Ø± Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø¨Ø§Ø´Ø¯
            start_row = 1 if skip_header else 0
            data_rows = all_data[start_row:]
            
            if not data_rows:
                return False, "âŒ Ø¨Ø¹Ø¯ Ø§Ø² Ø­Ø°Ù Ù‡Ø¯Ø±ØŒ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø§Ù‚ÛŒ Ù†Ù…Ø§Ù†Ø¯!", None
            
            # Ø¯Ø±ÛŒØ§ÙØª headers
            headers = all_data[0] if all_data else []
            
            # Ø§ÛŒØ¬Ø§Ø¯ SheetImport
            sheet_import = SheetImport(
                sheet_name=sheet_name,
                sheet_type=sheet_type,
                platform=platform,
                source_url=sheet_url,
                total_rows=len(data_rows),
                processed_rows=0,
                import_date=datetime.now(),
                notes=f"Imported from worksheet: {worksheet_name}"
            )
            self.db.add(sheet_import)
            self.db.flush()  # Ø¨Ø±Ø§ÛŒ Ú¯Ø±ÙØªÙ† ID
            
            self.logger.info(f"ğŸ“Š SheetImport Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯ Ø¨Ø§ ID: {sheet_import.id}")
            
            # Ø°Ø®ÛŒØ±Ù‡ Ù‡Ø± Ø³Ø·Ø± Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† RawData
            raw_data_list = []
            for idx, row in enumerate(data_rows, start=1):
                # ØªØ¨Ø¯ÛŒÙ„ row Ø¨Ù‡ dictionary Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² headers
                row_dict = {}
                for col_idx, value in enumerate(row):
                    if col_idx < len(headers):
                        col_name = headers[col_idx]
                        row_dict[col_name] = value
                    else:
                        # Ø§Ú¯Ø± Ø³ØªÙˆÙ†ÛŒ header Ù†Ø¯Ø§Ø´Øª
                        row_dict[f"Column_{col_idx + 1}"] = value
                
                raw_data = RawData(
                    sheet_import_id=sheet_import.id,
                    row_number=idx,
                    data=row_dict,  # SQLAlchemy Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù‡ JSON ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
                    processed=False
                )
                raw_data_list.append(raw_data)
            
            self.db.bulk_save_objects(raw_data_list)
            self.db.commit()
            
            success_msg = f"âœ… Import Ù…ÙˆÙÙ‚: {len(data_rows)} Ø³Ø·Ø± Ø§Ø² '{worksheet_name}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯!"
            self.logger.success(success_msg)
            
            return True, success_msg, sheet_import.id
            
        except Exception as e:
            self.db.rollback()
            error_msg = f"âŒ Ø®Ø·Ø§ Ø¯Ø± import: {str(e)}"
            self.logger.error(error_msg)
            return False, error_msg, None
    
    def get_import_preview(self, sheet_import_id: int, max_rows: int = 5) -> Dict:
        """
        Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ import Ø´Ø¯Ù‡
        
        Returns:
            {
                'sheet_info': {...},
                'columns': [...],
                'sample_rows': [...]
            }
        """
        try:
            sheet_import = self.db.query(SheetImport).filter_by(id=sheet_import_id).first()
            if not sheet_import:
                return {"error": "SheetImport ÛŒØ§ÙØª Ù†Ø´Ø¯!"}
            
            # Ø¯Ø±ÛŒØ§ÙØª Ú†Ù†Ø¯ Ø³Ø·Ø± Ù†Ù…ÙˆÙ†Ù‡
            sample_rows = self.db.query(RawData)\
                .filter_by(sheet_import_id=sheet_import_id)\
                .order_by(RawData.row_number)\
                .limit(max_rows)\
                .all()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
            columns = []
            if sample_rows:
                first_row_data = sample_rows[0].data
                columns = list(first_row_data.keys())
            
            return {
                'sheet_info': {
                    'id': sheet_import.id,
                    'name': sheet_import.sheet_name,
                    'type': sheet_import.sheet_type.value,
                    'platform': sheet_import.platform,
                    'total_rows': sheet_import.total_rows,
                    'processed_rows': sheet_import.processed_rows,
                    'import_date': sheet_import.import_date.strftime('%Y-%m-%d %H:%M')
                },
                'columns': columns,
                'sample_rows': [
                    {
                        'row_number': row.row_number,
                        'data': row.data,
                        'processed': row.processed
                    }
                    for row in sample_rows
                ]
            }
            
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´: {str(e)}")
            return {"error": str(e)}
    
    def get_all_imports(self) -> List[Dict]:
        """Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… importÙ‡Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡"""
        try:
            imports = self.db.query(SheetImport)\
                .order_by(SheetImport.import_date.desc())\
                .all()
            
            return [
                {
                    'id': imp.id,
                    'name': imp.sheet_name,
                    'type': imp.sheet_type.value,
                    'platform': imp.platform,
                    'total_rows': imp.total_rows,
                    'processed_rows': imp.processed_rows,
                    'progress': f"{imp.processed_rows}/{imp.total_rows}",
                    'import_date': imp.import_date.strftime('%Y-%m-%d %H:%M')
                }
                for imp in imports
            ]
        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª imports: {str(e)}")
            return []
